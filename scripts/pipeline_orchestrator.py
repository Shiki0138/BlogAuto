#!/usr/bin/env python3
"""
ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ - ãƒ•ã‚§ãƒ¼ã‚º3å®Ÿè£…
å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ±åˆå®Ÿè¡Œã¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†
"""
import os
import sys
import json
import time
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from scripts.utils import (
    logger, ensure_output_dir, save_json_safely,
    get_jst_now, health_checker, performance_monitor,
    run_integration_test
)

class PipelineOrchestrator:
    """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, enable_external_api: bool = False):
        """åˆæœŸåŒ–
        
        Args:
            enable_external_api: å¤–éƒ¨APIæ¥ç¶šã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã‹
        """
        self.output_dir = ensure_output_dir()
        self.execution_id = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.enable_external_api = enable_external_api
        
        # ç’°å¢ƒå¤‰æ•°è¨­å®š
        if self.enable_external_api:
            os.environ['ENABLE_EXTERNAL_API'] = 'true'
            logger.info("ğŸŒ å¤–éƒ¨APIæ¥ç¶šãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹")
        else:
            os.environ['ENABLE_EXTERNAL_API'] = 'false'
            logger.info("ğŸ”’ ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ¼ãƒ‰ï¼ˆå¤–éƒ¨APIæ¥ç¶šç„¡åŠ¹ï¼‰")
        
        self.pipeline_state = {
            "execution_id": self.execution_id,
            "start_time": None,
            "end_time": None,
            "stages": {},
            "overall_status": "pending",
            "external_api_enabled": self.enable_external_api
        }
        
    def execute_stage(self, stage_name: str, script_path: str, 
                     required_files: List[str] = None, 
                     output_files: List[str] = None) -> bool:
        """ã‚¹ãƒ†ãƒ¼ã‚¸å®Ÿè¡Œ"""
        try:
            logger.info(f"ã‚¹ãƒ†ãƒ¼ã‚¸é–‹å§‹: {stage_name}")
            
            stage_start = time.time()
            
            # å‰ææ¡ä»¶ãƒã‚§ãƒƒã‚¯
            if required_files:
                missing_files = [f for f in required_files if not Path(f).exists()]
                if missing_files:
                    logger.error(f"å¿…è¦ãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸è¶³: {missing_files}")
                    self.pipeline_state["stages"][stage_name] = {
                        "status": "failed",
                        "error": f"Missing files: {missing_files}",
                        "duration": 0
                    }
                    return False
            
            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œ
            import subprocess
            result = subprocess.run(
                ['python', script_path],
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            stage_duration = time.time() - stage_start
            
            if result.returncode == 0:
                # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
                if output_files:
                    missing_outputs = [f for f in output_files if not Path(f).exists()]
                    if missing_outputs:
                        logger.warning(f"æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_outputs}")
                
                self.pipeline_state["stages"][stage_name] = {
                    "status": "success",
                    "duration": stage_duration,
                    "stdout": result.stdout,
                    "output_files": output_files or []
                }
                logger.info(f"ã‚¹ãƒ†ãƒ¼ã‚¸å®Œäº†: {stage_name} ({stage_duration:.2f}ç§’)")
                return True
            else:
                self.pipeline_state["stages"][stage_name] = {
                    "status": "failed",
                    "duration": stage_duration,
                    "error": result.stderr,
                    "stdout": result.stdout
                }
                logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¸å¤±æ•—: {stage_name} - {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            self.pipeline_state["stages"][stage_name] = {
                "status": "timeout",
                "duration": 300,
                "error": "Script execution timeout"
            }
            logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {stage_name}")
            return False
        except Exception as e:
            self.pipeline_state["stages"][stage_name] = {
                "status": "error",
                "duration": 0,
                "error": str(e)
            }
            logger.error(f"ã‚¹ãƒ†ãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼: {stage_name} - {e}")
            return False
    
    def run_full_pipeline(self) -> bool:
        """å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        try:
            logger.info("ãƒ–ãƒ­ã‚°è‡ªå‹•åŒ–ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")
            self.pipeline_state["start_time"] = get_jst_now().isoformat()
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸1: è¨˜äº‹ç”Ÿæˆ
            success1 = self.execute_stage(
                stage_name="article_generation",
                script_path="scripts/generate_article.py",
                output_files=["output/article.md", "output/meta.json"]
            )
            
            if not success1:
                logger.error("è¨˜äº‹ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.pipeline_state["overall_status"] = "failed"
                return False
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸2: ç”»åƒå–å¾—
            success2 = self.execute_stage(
                stage_name="image_fetching",
                script_path="scripts/fetch_image.py",
                output_files=["output/image_info.json"]
            )
            
            # ç”»åƒå–å¾—ã¯å¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œ
            if not success2:
                logger.warning("ç”»åƒå–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
            
            # ã‚¹ãƒ†ãƒ¼ã‚¸3: WordPressæŠ•ç¨¿
            success3 = self.execute_stage(
                stage_name="wordpress_posting",
                script_path="scripts/post_to_wp.py",
                required_files=["output/article.md", "output/meta.json"],
                output_files=["output/wp_result.json"]
            )
            
            if not success3:
                logger.error("WordPressæŠ•ç¨¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
                self.pipeline_state["overall_status"] = "failed"
                return False
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†
            self.pipeline_state["end_time"] = get_jst_now().isoformat()
            self.pipeline_state["overall_status"] = "success"
            
            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±è¿½åŠ 
            total_duration = sum(
                stage.get("duration", 0) 
                for stage in self.pipeline_state["stages"].values()
            )
            self.pipeline_state["total_duration"] = total_duration
            
            logger.info(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† (åˆè¨ˆæ™‚é–“: {total_duration:.2f}ç§’)")
            return True
            
        except Exception as e:
            logger.error(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            self.pipeline_state["overall_status"] = "error"
            self.pipeline_state["error"] = str(e)
            return False
        
        finally:
            # å®Ÿè¡Œçµæœä¿å­˜
            self.save_pipeline_report()
    
    def save_pipeline_report(self):
        """ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        try:
            report_path = self.output_dir / f"pipeline_report_{self.execution_id}.json"
            save_json_safely(self.pipeline_state, str(report_path))
            
            # æœ€æ–°ãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ã‚‚ã‚³ãƒ”ãƒ¼
            latest_report_path = self.output_dir / "pipeline_report_latest.json"
            save_json_safely(self.pipeline_state, str(latest_report_path))
            
            logger.info(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
        except Exception as e:
            logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_health_check(self) -> bool:
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        try:
            logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯é–‹å§‹")
            
            health_results = health_checker.run_all_checks()
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœä¿å­˜
            health_report_path = self.output_dir / "health_check_latest.json"
            save_json_safely(health_results, str(health_report_path))
            
            is_healthy = health_results["overall_status"] == "healthy"
            
            if is_healthy:
                logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: æ­£å¸¸")
            else:
                logger.warning("ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: å•é¡Œã‚ã‚Š")
                for check_name, check_result in health_results["checks"].items():
                    if check_result["status"] != "pass":
                        logger.warning(f"  - {check_name}: {check_result}")
            
            return is_healthy
            
        except Exception as e:
            logger.error(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def run_integration_tests(self) -> bool:
        """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        try:
            logger.info("çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
            return run_integration_test()
        except Exception as e:
            logger.error(f"çµ±åˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return False

class WorkflowManager:
    """ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, enable_external_api: bool = False):
        self.orchestrator = PipelineOrchestrator(enable_external_api)
        
    def run_daily_workflow(self) -> bool:
        """æ—¥æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        try:
            logger.info("=== æ—¥æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹ ===")
            
            # 1. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
            health_ok = self.orchestrator.run_health_check()
            if not health_ok:
                logger.warning("ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸãŒã€å‡¦ç†ã‚’ç¶šè¡Œã—ã¾ã™")
            
            # 2. çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if os.getenv('RUN_INTEGRATION_TESTS', 'false').lower() == 'true':
                test_ok = self.orchestrator.run_integration_tests()
                if not test_ok:
                    logger.error("çµ±åˆãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    return False
            
            # 3. ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
            pipeline_ok = self.orchestrator.run_full_pipeline()
            
            if pipeline_ok:
                logger.info("=== æ—¥æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ­£å¸¸å®Œäº† ===")
            else:
                logger.error("=== æ—¥æ¬¡ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤±æ•— ===")
            
            return pipeline_ok
            
        except Exception as e:
            logger.error(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def run_test_workflow(self) -> bool:
        """ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        try:
            logger.info("=== ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹ ===")
            
            # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã®ã¿å®Ÿè¡Œ
            health_ok = self.orchestrator.run_health_check()
            
            # çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            test_ok = self.orchestrator.run_integration_tests()
            
            success = health_ok and test_ok
            
            if success:
                logger.info("=== ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼æ­£å¸¸å®Œäº† ===")
            else:
                logger.error("=== ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤±æ•— ===")
            
            return success
            
        except Exception as e:
            logger.error(f"ãƒ†ã‚¹ãƒˆãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")
            return False

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    
    try:
        parser = argparse.ArgumentParser(description='BlogAuto Pipeline Orchestrator')
        parser.add_argument(
            'workflow_type',
            choices=['daily', 'test', 'health', 'integration', 'api-test'],
            nargs='?',
            default='daily',
            help='å®Ÿè¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼: dailyï¼ˆæ—¥æ¬¡å®Ÿè¡Œï¼‰, testï¼ˆãƒ†ã‚¹ãƒˆï¼‰, healthï¼ˆãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼‰, integrationï¼ˆçµ±åˆãƒ†ã‚¹ãƒˆï¼‰, api-testï¼ˆAPIçµ±åˆãƒ†ã‚¹ãƒˆï¼‰'
        )
        parser.add_argument(
            '--enable-api',
            action='store_true',
            help='å¤–éƒ¨APIæ¥ç¶šã‚’æœ‰åŠ¹åŒ–'
        )
        
        args = parser.parse_args()
        
        # APIçµ±åˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯è‡ªå‹•çš„ã«APIæœ‰åŠ¹åŒ–
        if args.workflow_type == 'api-test':
            args.enable_api = True
        
        manager = WorkflowManager(enable_external_api=args.enable_api)
        
        if args.workflow_type in ['test', 'api-test']:
            success = manager.run_test_workflow()
        elif args.workflow_type == 'health':
            success = manager.orchestrator.run_health_check()
        elif args.workflow_type == 'integration':
            success = manager.orchestrator.run_integration_tests()
        else:
            success = manager.run_daily_workflow()
        
        if success:
            print(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼({args.workflow_type})ãŒæ­£å¸¸å®Œäº†ã—ã¾ã—ãŸ")
            if args.enable_api:
                print("âœ… å¤–éƒ¨APIçµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")
            sys.exit(0)
        else:
            print(f"ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼({args.workflow_type})ãŒå¤±æ•—ã—ã¾ã—ãŸ")
            sys.exit(1)
            
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()