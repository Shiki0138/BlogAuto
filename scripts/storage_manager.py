#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Storage API Manager - Final Phase Implementation
ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸APIçµ±åˆãƒ»ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAWS S3, Google Cloud Storage, Azure Blobï¼‰
"""
import os
import sys
import json
import boto3
import logging
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime
import hashlib
import mimetypes

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

try:
    from scripts.utils import logger, get_env_var, save_json_safely
    from scripts.auth_manager import SecureEnvironment, AuthManager
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    def get_env_var(key, required=True, default=None):
        value = os.getenv(key, default)
        if required and not value:
            logger.error(f"Required environment variable {key} not set")
        return value
    
    def save_json_safely(data, filepath):
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True

class StorageProvider:
    """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def upload_file(self, local_path: str, remote_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        raise NotImplementedError
    
    def download_file(self, remote_path: str, local_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        raise NotImplementedError
    
    def delete_file(self, remote_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        raise NotImplementedError
    
    def list_files(self, prefix: str = "") -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—"""
        raise NotImplementedError

class S3StorageProvider(StorageProvider):
    """AWS S3ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.aws_access_key = get_env_var('AWS_ACCESS_KEY_ID', required=False)
        self.aws_secret_key = get_env_var('AWS_SECRET_ACCESS_KEY', required=False)
        self.bucket_name = get_env_var('S3_BUCKET_NAME', required=False)
        self.region = get_env_var('AWS_REGION', required=False, default='us-east-1')
        
        # å¤–éƒ¨APIæ¥ç¶šãƒ•ãƒ©ã‚°ç¢ºèª
        self.enable_api = os.getenv('ENABLE_EXTERNAL_API', 'false').lower() == 'true'
        self.mock_mode = not self.enable_api or not all([
            self.aws_access_key, self.aws_secret_key, self.bucket_name
        ])
        
        if self.mock_mode:
            logger.info("S3ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: ãƒ¢ãƒƒã‚¯å‹•ä½œï¼ˆå¤–éƒ¨APIæ¥ç¶šç„¡åŠ¹ï¼‰")
            self.client = None
        else:
            try:
                self.client = boto3.client(
                    's3',
                    aws_access_key_id=self.aws_access_key,
                    aws_secret_access_key=self.aws_secret_key,
                    region_name=self.region
                )
                logger.info("S3ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸: æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰æ¥ç¶šå®Œäº†")
            except Exception as e:
                logger.error(f"S3æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                self.mock_mode = True
                self.client = None
    
    def upload_file(self, local_path: str, remote_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        try:
            if self.mock_mode:
                logger.info(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {local_path} â†’ {remote_path}")
                return f"https://mock-s3-bucket.s3.amazonaws.com/{remote_path}"
            
            if not Path(local_path).exists():
                logger.error(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {local_path}")
                return None
            
            # MIMEã‚¿ã‚¤ãƒ—æ¤œå‡º
            content_type, _ = mimetypes.guess_type(local_path)
            if not content_type:
                content_type = 'application/octet-stream'
            
            # S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
            extra_args = {
                'ContentType': content_type,
                'ACL': 'public-read'
            }
            
            self.client.upload_file(
                local_path, 
                self.bucket_name, 
                remote_path, 
                ExtraArgs=extra_args
            )
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰URLç”Ÿæˆ
            url = f"https://{self.bucket_name}.s3.{self.region}.amazonaws.com/{remote_path}"
            logger.info(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {url}")
            return url
            
        except Exception as e:
            logger.error(f"S3ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def download_file(self, remote_path: str, local_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
        try:
            if self.mock_mode:
                logger.info(f"S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {remote_path} â†’ {local_path}")
                # ãƒ¢ãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
                Path(local_path).parent.mkdir(parents=True, exist_ok=True)
                Path(local_path).write_text("mock file content")
                return True
            
            self.client.download_file(self.bucket_name, remote_path, local_path)
            logger.info(f"S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†: {local_path}")
            return True
            
        except Exception as e:
            logger.error(f"S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def delete_file(self, remote_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤"""
        try:
            if self.mock_mode:
                logger.info(f"S3å‰Šé™¤ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {remote_path}")
                return True
            
            self.client.delete_object(Bucket=self.bucket_name, Key=remote_path)
            logger.info(f"S3å‰Šé™¤å®Œäº†: {remote_path}")
            return True
            
        except Exception as e:
            logger.error(f"S3å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def list_files(self, prefix: str = "") -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—"""
        try:
            if self.mock_mode:
                logger.info(f"S3ãƒªã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: prefix={prefix}")
                return [
                    f"{prefix}mock-file-1.jpg",
                    f"{prefix}mock-file-2.md",
                    f"{prefix}mock-file-3.json"
                ]
            
            response = self.client.list_objects_v2(
                Bucket=self.bucket_name,
                Prefix=prefix
            )
            
            files = []
            if 'Contents' in response:
                files = [obj['Key'] for obj in response['Contents']]
            
            logger.info(f"S3ãƒªã‚¹ãƒˆå–å¾—å®Œäº†: {len(files)}ä»¶")
            return files
            
        except Exception as e:
            logger.error(f"S3ãƒªã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return []

class GoogleCloudStorageProvider(StorageProvider):
    """Google Cloud Storageãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆãƒ¢ãƒƒã‚¯å®Ÿè£…ï¼‰"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.mock_mode = True  # ç¾æ®µéšã§ã¯ãƒ¢ãƒƒã‚¯å‹•ä½œã®ã¿
        logger.info("Google Cloud Storage: ãƒ¢ãƒƒã‚¯å‹•ä½œ")
    
    def upload_file(self, local_path: str, remote_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"GCSã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {local_path} â†’ {remote_path}")
        return f"https://storage.googleapis.com/mock-bucket/{remote_path}"
    
    def download_file(self, remote_path: str, local_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"GCSãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {remote_path} â†’ {local_path}")
        Path(local_path).parent.mkdir(parents=True, exist_ok=True)
        Path(local_path).write_text("mock gcs content")
        return True
    
    def delete_file(self, remote_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"GCSå‰Šé™¤ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {remote_path}")
        return True
    
    def list_files(self, prefix: str = "") -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"GCSãƒªã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: prefix={prefix}")
        return [f"{prefix}gcs-mock-{i}.jpg" for i in range(3)]

class AzureBlobProvider(StorageProvider):
    """Azure Blob Storageãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ï¼ˆãƒ¢ãƒƒã‚¯å®Ÿè£…ï¼‰"""
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.mock_mode = True  # ç¾æ®µéšã§ã¯ãƒ¢ãƒƒã‚¯å‹•ä½œã®ã¿
        logger.info("Azure Blob Storage: ãƒ¢ãƒƒã‚¯å‹•ä½œ")
    
    def upload_file(self, local_path: str, remote_path: str) -> Optional[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"Azureã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {local_path} â†’ {remote_path}")
        return f"https://mockaccount.blob.core.windows.net/container/{remote_path}"
    
    def download_file(self, remote_path: str, local_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"Azureãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {remote_path} â†’ {local_path}")
        Path(local_path).parent.mkdir(parents=True, exist_ok=True)
        Path(local_path).write_text("mock azure content")
        return True
    
    def delete_file(self, remote_path: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"Azureå‰Šé™¤ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: {remote_path}")
        return True
    
    def list_files(self, prefix: str = "") -> List[str]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        logger.info(f"Azureãƒªã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰: prefix={prefix}")
        return [f"{prefix}azure-mock-{i}.jpg" for i in range(3)]

class StorageManager:
    """çµ±åˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        """åˆæœŸåŒ–"""
        self.providers = {}
        self.active_provider = None
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–
        self._initialize_providers()
        self._select_active_provider()
        
        logger.info("StorageManager initialized")
    
    def _initialize_providers(self):
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–"""
        try:
            # AWS S3
            self.providers['s3'] = S3StorageProvider()
            
            # Google Cloud Storage
            self.providers['gcs'] = GoogleCloudStorageProvider()
            
            # Azure Blob Storage
            self.providers['azure'] = AzureBlobProvider()
            
            logger.info("ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–å®Œäº†")
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _select_active_provider(self):
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼é¸æŠ"""
        # å„ªå…ˆé †ä½: S3 â†’ GCS â†’ Azure
        preferred_order = ['s3', 'gcs', 'azure']
        
        for provider_name in preferred_order:
            if provider_name in self.providers:
                self.active_provider = provider_name
                logger.info(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {provider_name}")
                break
    
    def upload_blog_assets(self, article_date: str) -> Dict[str, Any]:
        """ãƒ–ãƒ­ã‚°ã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"""
        try:
            logger.info("ãƒ–ãƒ­ã‚°ã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹")
            
            results = {
                'success': False,
                'uploaded_files': [],
                'urls': {},
                'provider': self.active_provider,
                'timestamp': datetime.now().isoformat()
            }
            
            # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«
            assets = [
                {
                    'local': 'output/article.md',
                    'remote': f"blog/{article_date}/article.md",
                    'type': 'article'
                },
                {
                    'local': 'output/meta.json',
                    'remote': f"blog/{article_date}/meta.json",
                    'type': 'metadata'
                },
                {
                    'local': 'output/cover.jpg',
                    'remote': f"blog/{article_date}/cover.jpg",
                    'type': 'image'
                },
                {
                    'local': 'output/image_info.json',
                    'remote': f"blog/{article_date}/image_info.json",
                    'type': 'image_info'
                }
            ]
            
            provider = self.providers[self.active_provider]
            uploaded_count = 0
            
            for asset in assets:
                local_path = asset['local']
                remote_path = asset['remote']
                
                if Path(local_path).exists():
                    url = provider.upload_file(local_path, remote_path)
                    if url:
                        results['uploaded_files'].append({
                            'local_path': local_path,
                            'remote_path': remote_path,
                            'url': url,
                            'type': asset['type']
                        })
                        results['urls'][asset['type']] = url
                        uploaded_count += 1
                        logger.info(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {local_path} â†’ {url}")
                    else:
                        logger.warning(f"ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {local_path}")
                else:
                    logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {local_path}")
            
            results['success'] = uploaded_count > 0
            results['total_uploaded'] = uploaded_count
            
            # çµæœä¿å­˜
            save_json_safely(results, 'output/storage_results.json')
            
            logger.info(f"ãƒ–ãƒ­ã‚°ã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {uploaded_count}ä»¶æˆåŠŸ")
            return results
            
        except Exception as e:
            logger.error(f"ãƒ–ãƒ­ã‚°ã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def backup_system_files(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—"""
        try:
            logger.info("ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹")
            
            backup_date = datetime.now().strftime('%Y%m%d_%H%M%S')
            results = {
                'success': False,
                'backup_date': backup_date,
                'backed_up_files': [],
                'provider': self.active_provider
            }
            
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¯¾è±¡
            system_files = [
                'README.md',
                'requirements.txt',
                '.env.example',
                'development/development_log.txt',
                'specifications/project_spec.md'
            ]
            
            provider = self.providers[self.active_provider]
            backup_count = 0
            
            for file_path in system_files:
                if Path(file_path).exists():
                    remote_path = f"backups/{backup_date}/{file_path}"
                    url = provider.upload_file(file_path, remote_path)
                    if url:
                        results['backed_up_files'].append({
                            'file': file_path,
                            'remote_path': remote_path,
                            'url': url
                        })
                        backup_count += 1
            
            results['success'] = backup_count > 0
            results['total_backed_up'] = backup_count
            
            logger.info(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_count}ä»¶")
            return results
            
        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'success': False, 'error': str(e)}
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆå–å¾—"""
        try:
            provider = self.providers[self.active_provider]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
            blog_files = provider.list_files('blog/')
            backup_files = provider.list_files('backups/')
            
            stats = {
                'provider': self.active_provider,
                'total_blog_files': len(blog_files),
                'total_backup_files': len(backup_files),
                'recent_blog_files': blog_files[-10:] if blog_files else [],
                'recent_backup_files': backup_files[-5:] if backup_files else [],
                'timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆ: ãƒ–ãƒ­ã‚°{len(blog_files)}ä»¶ã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—{len(backup_files)}ä»¶")
            return stats
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {'error': str(e)}

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    try:
        logger.info("ğŸ—„ï¸  ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸APIçµ±åˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        storage_manager = StorageManager()
        
        # ç¾åœ¨æ—¥ä»˜å–å¾—
        today = datetime.now().strftime('%Y%m%d')
        
        # ãƒ–ãƒ­ã‚°ã‚¢ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        upload_results = storage_manager.upload_blog_assets(today)
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
        backup_results = storage_manager.backup_system_files()
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸çµ±è¨ˆå–å¾—
        storage_stats = storage_manager.get_storage_stats()
        
        # å®Œäº†ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        final_report = {
            'storage_integration_complete': True,
            'upload_results': upload_results,
            'backup_results': backup_results,
            'storage_stats': storage_stats,
            'active_provider': storage_manager.active_provider,
            'completion_time': datetime.now().isoformat()
        }
        
        save_json_safely(final_report, 'output/storage_integration_report.json')
        
        logger.info("âœ… ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸APIçµ±åˆå®Œäº†")
        logger.info(f"ğŸ“Š ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {upload_results.get('total_uploaded', 0)}ä»¶")
        logger.info(f"ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_results.get('total_backed_up', 0)}ä»¶")
        logger.info(f"ğŸ—ƒï¸  ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: {storage_manager.active_provider}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸APIçµ±åˆã‚¨ãƒ©ãƒ¼: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)