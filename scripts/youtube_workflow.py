#!/usr/bin/env python3
"""
YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
@shiki_138ãƒãƒ£ãƒ³ãƒãƒ«ã®å‹•ç”»ã‚’ãƒ–ãƒ­ã‚°è¨˜äº‹ã«å¤‰æ›ã™ã‚‹å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
import json

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

try:
    from scripts.utils import logger, ensure_output_dir, save_json_safely
    from scripts.fetch_transcript import YouTubeTranscriptFetcher
    from scripts.generate_article import ArticleGenerator
except ImportError:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    def ensure_output_dir():
        output_dir = Path('output')
        output_dir.mkdir(exist_ok=True)
        return output_dir
    
    def save_json_safely(data, file_path):
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

class YouTubeWorkflow:
    """@shiki_138ãƒãƒ£ãƒ³ãƒãƒ«å‘ã‘YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼"""
    
    def __init__(self):
        self.output_dir = ensure_output_dir()
        self.channel = "@shiki_138"
        logger.info(f"YouTubeWorkflow initialized for {self.channel}")
    
    def run_full_workflow(self) -> dict:
        """å®Œå…¨è‡ªå‹•YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Ÿè¡Œ"""
        try:
            logger.info("ğŸ¬ YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼é–‹å§‹")
            
            workflow_result = {
                'workflow_id': f"youtube_workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'start_time': datetime.now().isoformat(),
                'channel': self.channel,
                'steps': {},
                'success': False
            }
            
            # ã‚¹ãƒ†ãƒƒãƒ—1: YouTubeå‹•ç”»ãƒ‡ãƒ¼ã‚¿å–å¾—
            logger.info("ğŸ“º ã‚¹ãƒ†ãƒƒãƒ—1: @shiki_138ã®æœ€æ–°å‹•ç”»å–å¾—")
            step1_result = self._step1_fetch_youtube_data()
            workflow_result['steps']['fetch_youtube_data'] = step1_result
            
            if not step1_result['success']:
                raise Exception("YouTubeå‹•ç”»ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—")
            
            # ã‚¹ãƒ†ãƒƒãƒ—2: è¨˜äº‹ç”Ÿæˆ
            logger.info("ğŸ“ ã‚¹ãƒ†ãƒƒãƒ—2: YouTubeå‹•ç”»ãƒ™ãƒ¼ã‚¹è¨˜äº‹ç”Ÿæˆ")
            step2_result = self._step2_generate_article(step1_result['data'])
            workflow_result['steps']['generate_article'] = step2_result
            
            if not step2_result['success']:
                raise Exception("è¨˜äº‹ç”Ÿæˆã«å¤±æ•—")
            
            # ã‚¹ãƒ†ãƒƒãƒ—3: å“è³ªãƒã‚§ãƒƒã‚¯
            logger.info("ğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: è¨˜äº‹å“è³ªãƒã‚§ãƒƒã‚¯")
            step3_result = self._step3_quality_check()
            workflow_result['steps']['quality_check'] = step3_result
            
            # ã‚¹ãƒ†ãƒƒãƒ—4: å‡ºåŠ›çµ±åˆ
            logger.info("ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—4: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆ")
            step4_result = self._step4_integrate_outputs(workflow_result)
            workflow_result['steps']['integrate_outputs'] = step4_result
            
            # å®Œäº†å‡¦ç†
            workflow_result['end_time'] = datetime.now().isoformat()
            workflow_result['success'] = True
            workflow_result['message'] = "@shiki_138ãƒãƒ£ãƒ³ãƒãƒ«é€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†"
            
            # ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµæœä¿å­˜
            result_file = self.output_dir / 'youtube_workflow_result.json'
            save_json_safely(workflow_result, result_file)
            
            logger.info("âœ… YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†")
            logger.info(f"ğŸ“Š çµæœãƒ•ã‚¡ã‚¤ãƒ«: {result_file}")
            
            return workflow_result
            
        except Exception as e:
            logger.error(f"âŒ YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤±æ•—: {e}")
            
            error_result = {
                'workflow_id': f"youtube_workflow_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                'start_time': workflow_result.get('start_time', datetime.now().isoformat()),
                'end_time': datetime.now().isoformat(),
                'channel': self.channel,
                'success': False,
                'error': str(e),
                'steps': workflow_result.get('steps', {})
            }
            
            return error_result
    
    def _step1_fetch_youtube_data(self) -> dict:
        """ã‚¹ãƒ†ãƒƒãƒ—1: YouTubeå‹•ç”»ãƒ‡ãƒ¼ã‚¿å–å¾—"""
        try:
            fetcher = YouTubeTranscriptFetcher()
            blog_data = fetcher.fetch_channel_latest_video()
            
            if blog_data.get('success', True):
                return {
                    'success': True,
                    'data': blog_data,
                    'video_title': blog_data['video_info']['title'],
                    'video_id': blog_data['video_info']['video_id'],
                    'transcript_length': len(blog_data['transcript_result']['transcript']['cleaned_text']),
                    'execution_time': datetime.now().isoformat()
                }
            else:
                raise Exception(f"YouTubeå‹•ç”»å–å¾—å¤±æ•—: {blog_data.get('error')}")
                
        except Exception as e:
            logger.error(f"ã‚¹ãƒ†ãƒƒãƒ—1ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'execution_time': datetime.now().isoformat()
            }
    
    def _step2_generate_article(self, youtube_data: dict) -> dict:
        """ã‚¹ãƒ†ãƒƒãƒ—2: è¨˜äº‹ç”Ÿæˆ"""
        try:
            generator = ArticleGenerator()
            
            # YouTubeé€£æºè¨˜äº‹ç”Ÿæˆ
            success = generator.generate_youtube_article(
                youtube_data['video_info'],
                youtube_data['transcript_result']['transcript']['cleaned_text']
            )
            
            if success:
                # ç”Ÿæˆã•ã‚ŒãŸè¨˜äº‹ã®æƒ…å ±ã‚’å–å¾—
                article_path = generator.output_dir / "article.md"
                meta_path = generator.output_dir / "meta.json"
                
                article_content = ""
                metadata = {}
                
                if article_path.exists():
                    article_content = article_path.read_text(encoding='utf-8')
                
                if meta_path.exists():
                    with open(meta_path, 'r', encoding='utf-8') as f:
                        metadata = json.load(f)
                
                return {
                    'success': True,
                    'article_length': len(article_content),
                    'article_title': metadata.get('title', 'Unknown'),
                    'word_count': metadata.get('word_count', 0),
                    'tags_count': len(metadata.get('tags', [])),
                    'execution_time': datetime.now().isoformat()
                }
            else:
                raise Exception("è¨˜äº‹ç”Ÿæˆã«å¤±æ•—")
                
        except Exception as e:
            logger.error(f"ã‚¹ãƒ†ãƒƒãƒ—2ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'execution_time': datetime.now().isoformat()
            }
    
    def _step3_quality_check(self) -> dict:
        """ã‚¹ãƒ†ãƒƒãƒ—3: å“è³ªãƒã‚§ãƒƒã‚¯"""
        try:
            article_path = self.output_dir / "article.md"
            
            if not article_path.exists():
                raise Exception("è¨˜äº‹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            
            content = article_path.read_text(encoding='utf-8')
            
            # åŸºæœ¬çš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
            checks = {
                'length_check': len(content) >= 1800,  # æœ€ä½æ–‡å­—æ•°
                'title_check': content.startswith('#'),  # ã‚¿ã‚¤ãƒˆãƒ«ã®å­˜åœ¨
                'structure_check': '##' in content,  # è¦‹å‡ºã—æ§‹é€ 
                'youtube_reference': '@shiki_138' in content,  # YouTubeå‚ç…§
                'link_check': 'youtube.com' in content or 'youtu.be' in content  # å‹•ç”»ãƒªãƒ³ã‚¯
            }
            
            passed_checks = sum(checks.values())
            total_checks = len(checks)
            quality_score = (passed_checks / total_checks) * 100
            
            return {
                'success': True,
                'quality_score': quality_score,
                'passed_checks': passed_checks,
                'total_checks': total_checks,
                'check_details': checks,
                'execution_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒ†ãƒƒãƒ—3ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'execution_time': datetime.now().isoformat()
            }
    
    def _step4_integrate_outputs(self, workflow_result: dict) -> dict:
        """ã‚¹ãƒ†ãƒƒãƒ—4: å‡ºåŠ›çµ±åˆ"""
        try:
            # YouTubeé€£æºç”¨ã®çµ±åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
            integration_data = {
                'workflow_type': 'youtube_integration',
                'channel': self.channel,
                'workflow_id': workflow_result['workflow_id'],
                'processing_summary': {
                    'video_title': workflow_result['steps']['fetch_youtube_data']['data']['video_info']['title'],
                    'article_title': workflow_result['steps']['generate_article']['article_title'],
                    'quality_score': workflow_result['steps']['quality_check']['quality_score'],
                    'article_length': workflow_result['steps']['generate_article']['article_length']
                },
                'files_generated': [
                    'output/article.md',
                    'output/meta.json',
                    'output/transcript.txt',
                    'output/transcript_meta.json',
                    'output/shiki138_latest_blog_data.json',
                    'output/youtube_workflow_result.json'
                ],
                'integration_timestamp': datetime.now().isoformat()
            }
            
            # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            integration_file = self.output_dir / 'youtube_integration_summary.json'
            save_json_safely(integration_data, integration_file)
            
            return {
                'success': True,
                'integration_file': str(integration_file),
                'files_count': len(integration_data['files_generated']),
                'execution_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ã‚¹ãƒ†ãƒƒãƒ—4ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'success': False,
                'error': str(e),
                'execution_time': datetime.now().isoformat()
            }

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    
    print("ğŸ¬ YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ (@shiki_138)")
    print("=" * 50)
    
    workflow = YouTubeWorkflow()
    result = workflow.run_full_workflow()
    
    if result['success']:
        print("âœ… YouTubeé€£æºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å®Œäº†!")
        print(f"ğŸ“º ãƒãƒ£ãƒ³ãƒãƒ«: {result['channel']}")
        print(f"ğŸ¯ å“è³ªã‚¹ã‚³ã‚¢: {result['steps']['quality_check']['quality_score']:.1f}%")
        print(f"ğŸ“„ è¨˜äº‹æ–‡å­—æ•°: {result['steps']['generate_article']['article_length']} æ–‡å­—")
        print(f"ğŸ“ çµæœãƒ•ã‚¡ã‚¤ãƒ«: output/youtube_workflow_result.json")
    else:
        print(f"âŒ ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼å¤±æ•—: {result['error']}")
        
    return result['success']

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)